{"pageProps":{"postData":{"id":"the-art-of-prompt-engineering","contentHtml":"<p>Prompt engineering is quickly becoming the new digital literacy. If you’ve ever tried to get a language model to do something “just right” and found yourself tweaking your words over and over, you’ve already dipped your toes into this fascinating craft. After reading <a href=\"https://drive.google.com/file/d/1AbaBYbEa_EbPelsT40-vj64L-2IwUJHy/view\" target=\"_blank\" rel=\"nofollow\">Lee Boonstra’s book</a> on the subject, I realized that learning to prompt is much like learning a new language: you have to master its nuances, idioms, and even its quirks to get the best results.</p>\n<p>At its core, prompt engineering is about talking to AI in a way it understands and responds to effectively. Whether you’re summarizing text, extracting information, answering questions, translating languages or code, or even generating documentation, your prompt is your instruction manual. The clearer and more intentional you are, the better the AI performs.</p>\n<p>But it’s not just what you say—it’s how you configure the model’s output. There are a few essential dials to know:</p>\n<ul>\n<li><strong>Output length:</strong> Be specific. Too short, and you miss details; too long, and the model might ramble or fill with fluff. Example: “Summarize this article in 100 words.” or \"Explain quantum physics in a tweet-length message\"</li>\n<li><strong>Sampling controls:</strong> These include temperature, top-K, and top-P. Temperature controls randomness in the LLM's responses. At temperature 0, responses are deterministic and predictable – great for factual queries. Higher temperatures introduce creativity and variation – better for brainstorming or creative writing. Top-K and top-P further shape how “adventurous” the model is in picking the next word. For most tasks, a temperature of 0.2, top-P of 0.95, and top-K of 30 is a sweet spot for coherence with a dash of creativity.</li>\n<li><strong>Watch for repetition loops:</strong> If you notice the model repeating itself, try tweaking these settings—especially temperature and top-K.</li>\n</ul>\n<p>When it comes to crafting prompts, there’s a whole toolkit of techniques:</p>\n<ul>\n<li><strong>Zero-shot prompting</strong> is the simplest: just ask your question or give a command. \"Write a short poem about autumn.\"</li>\n<li><strong>One-shot and few-shot prompting</strong> involve giving one or more examples. This is especially helpful for classification or when you want a specific output structure. For example:</li>\n</ul>\n<pre><code class=\"code-highlight\"><span class=\"code-line line-number\" line=\"1\">Review: \"This movie was hilarious and heartwarming.\"\n</span><span class=\"code-line line-number\" line=\"2\">Sentiment: Positive\n</span><span class=\"code-line line-number\" line=\"3\">\n</span><span class=\"code-line line-number\" line=\"4\">Review: \"The plot was confusing and dull.\"\n</span><span class=\"code-line line-number\" line=\"5\">Sentiment:\n</span></code></pre>\n<ul>\n<li><strong>System, contextual, and role prompting</strong> add another layer of sophistication:\n<ul>\n<li><strong>System prompts</strong> set the “big picture” context—like telling the model to always return results in JSON, or to answer respectfully. Example: \"You are an expert Python programmer helping debug code.\"</li>\n<li><strong>Contextual prompts</strong> give task-specific instructions or information for the current task: \"Here's a function that's throwing an IndexError.\"</li>\n<li><strong>Role prompts</strong> let you assign a persona or style, like “You are a motivational speaker. Explain blockchain to a beginner.”</li>\n</ul>\n</li>\n</ul>\n<p>Some advanced techniques can boost performance on tricky tasks:</p>\n<ul>\n<li><strong>Step-back prompting:</strong> First ask the model a general question, then feed its answer into a more specific prompt.</li>\n<li><strong>Chain of Thought (CoT):</strong> Encourage the model to “think aloud” by breaking down its reasoning step by step.</li>\n<li><strong>Self-consistency:</strong> Run the same prompt multiple times with higher randomness, then pick the most common answer for reliability.</li>\n<li><strong>Tree of Thoughts (ToT):</strong> Explore multiple reasoning paths at once, not just one.</li>\n<li><strong>ReAct (Reason &#x26; Act):</strong> Combine reasoning with actions, like calling APIs or searching the web, for agent-like behavior.</li>\n<li><strong>Automatic Prompt Engineering:</strong> Use the model itself to generate and refine new prompts—a kind of meta-prompting.</li>\n</ul>\n<p>For more complex reasoning tasks, techniques like <strong>Chain of Thought</strong> (CoT) and <strong>Tree of Thoughts</strong> (ToT) can dramatically improve results. Chain of Thought encourages the model to \"think aloud\" by showing its reasoning step by step:</p>\n<pre><code class=\"code-highlight\"><span class=\"code-line line-number\" line=\"1\">Question: If John has 5 apples and gives 2 to Mary, then buys 3 more and eats 1, how many apples does John have?\n</span><span class=\"code-line line-number\" line=\"2\">Thinking: John starts with 5 apples. He gives 2 to Mary, so now he has 5-2=3 apples. Then he buys 3 more, so now he has 3+3=6 apples. Finally, he eats 1, so he has 6-1=5 apples.\n</span><span class=\"code-line line-number\" line=\"3\">Answer: 5 apples\n</span></code></pre>\n<p>Prompt engineering isn’t just for text. While it’s invaluable for code - writing, translating, explaining, analysis and reasoning all benefit from well-crafted prompts.</p>\n<p>So, what makes a good prompt? Here’s what I’ve found works best:</p>\n<ul>\n<li><strong>Provide examples</strong>—they’re the best way to “teach” the model.</li>\n<li><strong>Keep it simple and clear.</strong> If it confuses you, it’ll confuse the AI.</li>\n<li><strong>Use action verbs:</strong> Analyze, Summarize, Generate, List, etc.</li>\n<li><strong>Be specific about the output.</strong> “Return the answer as a JSON object with keys ‘city’ and ‘population’.”</li>\n<li><strong>Prefer instructions over constraints:</strong> “Write in a formal tone” is clearer than “Don’t be informal.”</li>\n<li><strong>Control token length:</strong> “Explain quantum physics in a tweet.”</li>\n<li><strong>Use variables when you use repetitive prompts with small differences:</strong> “Variables: {city}=Amsterdam\nPrompt: You are a travel guide. Tell me a fact about the city: {city}.”</li>\n<li><strong>Experiment with styles and formats.</strong> Try different prompt types, output formats (like JSON/XML), and even mix up your examples.</li>\n<li><strong>Document your attempts.</strong> Prompt engineering is iterative—track what works and what doesn’t.</li>\n</ul>\n<p>For more complex tasks, a structured prompt format can be a game-changer. Here’s a sample template you can adapt:</p>\n<pre><code class=\"code-highlight\"><span class=\"code-line line-number\" line=\"1\">&#x3C;OBJECTIVE_AND_PERSONA>\n</span><span class=\"code-line line-number\" line=\"2\">You are a [insert a persona, such as a \"math teacher\" or \"automotive expert\"]. Your task is to...\n</span><span class=\"code-line line-number\" line=\"3\">&#x3C;/OBJECTIVE_AND_PERSONA>\n</span><span class=\"code-line line-number\" line=\"4\">\n</span><span class=\"code-line line-number\" line=\"5\">&#x3C;INSTRUCTIONS>\n</span><span class=\"code-line line-number\" line=\"6\">To complete the task, you need to follow these steps:\n</span><span class=\"code-line line-number\" line=\"7\">1.\n</span><span class=\"code-line line-number\" line=\"8\">2.\n</span><span class=\"code-line line-number\" line=\"9\">...\n</span><span class=\"code-line line-number\" line=\"10\">&#x3C;/INSTRUCTIONS>\n</span><span class=\"code-line line-number\" line=\"11\">\n</span><span class=\"code-line line-number\" line=\"12\">------------- Optional Components ------------\n</span><span class=\"code-line line-number\" line=\"13\">\n</span><span class=\"code-line line-number\" line=\"14\">&#x3C;CONSTRAINTS>\n</span><span class=\"code-line line-number\" line=\"15\">Dos and don'ts for the following aspects\n</span><span class=\"code-line line-number\" line=\"16\">1. Dos\n</span><span class=\"code-line line-number\" line=\"17\">2. Don'ts\n</span><span class=\"code-line line-number\" line=\"18\">&#x3C;/CONSTRAINTS>\n</span><span class=\"code-line line-number\" line=\"19\">\n</span><span class=\"code-line line-number\" line=\"20\">&#x3C;CONTEXT>\n</span><span class=\"code-line line-number\" line=\"21\">The provided context\n</span><span class=\"code-line line-number\" line=\"22\">&#x3C;/CONTEXT>\n</span><span class=\"code-line line-number\" line=\"23\">\n</span><span class=\"code-line line-number\" line=\"24\">&#x3C;OUTPUT_FORMAT>\n</span><span class=\"code-line line-number\" line=\"25\">The output format must be\n</span><span class=\"code-line line-number\" line=\"26\">1.\n</span><span class=\"code-line line-number\" line=\"27\">2.\n</span><span class=\"code-line line-number\" line=\"28\">...\n</span><span class=\"code-line line-number\" line=\"29\">&#x3C;/OUTPUT_FORMAT>\n</span><span class=\"code-line line-number\" line=\"30\">\n</span><span class=\"code-line line-number\" line=\"31\">&#x3C;FEW_SHOT_EXAMPLES>\n</span><span class=\"code-line line-number\" line=\"32\">Here we provide some examples:\n</span><span class=\"code-line line-number\" line=\"33\">1. Example #1\n</span><span class=\"code-line line-number\" line=\"34\">    Input:\n</span><span class=\"code-line line-number\" line=\"35\">    Thoughts:\n</span><span class=\"code-line line-number\" line=\"36\">    Output:\n</span><span class=\"code-line line-number\" line=\"37\">...\n</span><span class=\"code-line line-number\" line=\"38\">&#x3C;/FEW_SHOT_EXAMPLES>\n</span><span class=\"code-line line-number\" line=\"39\">\n</span><span class=\"code-line line-number\" line=\"40\">&#x3C;RECAP>\n</span><span class=\"code-line line-number\" line=\"41\">Re-emphasize the key aspects of the prompt, especially the constraints, output format, etc.\n</span><span class=\"code-line line-number\" line=\"42\">&#x3C;/RECAP>\n</span></code></pre>\n<p>Let's see this in action with a simple example:</p>\n<pre><code class=\"code-highlight\"><span class=\"code-line line-number\" line=\"1\">&#x3C;OBJECTIVE_AND_PERSONA>\n</span><span class=\"code-line line-number\" line=\"2\">You are a travel blogger known for concise, vivid descriptions. Your task is to create engaging city descriptions.\n</span><span class=\"code-line line-number\" line=\"3\">&#x3C;/OBJECTIVE_AND_PERSONA>\n</span><span class=\"code-line line-number\" line=\"4\">\n</span><span class=\"code-line line-number\" line=\"5\">&#x3C;INSTRUCTIONS>\n</span><span class=\"code-line line-number\" line=\"6\">Create a 100-word description that captures the essence of the city I name.\n</span><span class=\"code-line line-number\" line=\"7\">&#x3C;/INSTRUCTIONS>\n</span><span class=\"code-line line-number\" line=\"8\">\n</span><span class=\"code-line line-number\" line=\"9\">&#x3C;OUTPUT_FORMAT>\n</span><span class=\"code-line line-number\" line=\"10\">A single paragraph of exactly 100 words that includes:\n</span><span class=\"code-line line-number\" line=\"11\">1. A striking opening line\n</span><span class=\"code-line line-number\" line=\"12\">2. Mention of one famous landmark\n</span><span class=\"code-line line-number\" line=\"13\">3. Reference to local cuisine\n</span><span class=\"code-line line-number\" line=\"14\">4. A sensory detail (sound, smell, etc.)\n</span><span class=\"code-line line-number\" line=\"15\">&#x3C;/OUTPUT_FORMAT>\n</span><span class=\"code-line line-number\" line=\"16\">\n</span><span class=\"code-line line-number\" line=\"17\">&#x3C;FEW_SHOT_EXAMPLES>\n</span><span class=\"code-line line-number\" line=\"18\">City: Paris\n</span><span class=\"code-line line-number\" line=\"19\">Output: Paris whispers romance in every cobblestone alley and tree-lined boulevard. The Eiffel Tower stands as an iron sentinel, watching over centuries of love stories unfolding beneath its gaze. In quaint cafés, the aroma of fresh croissants mingles with rich espresso, tempting passersby to pause and indulge. Street musicians fill the air with accordion melodies that dance between historic buildings. Whether bathed in golden morning light or twinkling with evening stars, the City of Light captivates with a timeless charm that transforms visitors into lifelong admirers.\n</span><span class=\"code-line line-number\" line=\"20\">&#x3C;/FEW_SHOT_EXAMPLES>\n</span><span class=\"code-line line-number\" line=\"21\">\n</span><span class=\"code-line line-number\" line=\"22\">City: Tokyo\n</span></code></pre>\n<p>Prompt engineering is both an art and a science, requiring practice, experimentation, and a good understanding of how LLMs work. As these models continue to evolve, so too will the techniques we use to communicate with them. But mastering these fundamentals will give you a solid foundation for getting the most out of AI tools, whether for personal projects, creative endeavors, or professional applications.</p>\n<p>The journey of learning to speak AI's language is just the beginning. If you're interested in diving deeper into this fascinating field, I highly recommend checking out <a href=\"https://drive.google.com/file/d/1AbaBYbEa_EbPelsT40-vj64L-2IwUJHy/view\" target=\"_blank\" rel=\"nofollow\">Lee Boonstra's book</a> on Prompt Engineering, which provided the insights for this blog post. Even the <a href=\"https://cloud.google.com/vertex-ai/generative-ai/docs/learn/prompts/prompt-design-strategies\" target=\"_blank\" rel=\"nofollow\">Google's learning center material</a> around prompt engineering is a good starting point.</p>\n<p>What prompt engineering techniques have you found most effective? I'd love to hear about your experiences.</p>","content":"\nPrompt engineering is quickly becoming the new digital literacy. If you’ve ever tried to get a language model to do something “just right” and found yourself tweaking your words over and over, you’ve already dipped your toes into this fascinating craft. After reading [Lee Boonstra’s book](https://drive.google.com/file/d/1AbaBYbEa_EbPelsT40-vj64L-2IwUJHy/view) on the subject, I realized that learning to prompt is much like learning a new language: you have to master its nuances, idioms, and even its quirks to get the best results.\n\nAt its core, prompt engineering is about talking to AI in a way it understands and responds to effectively. Whether you’re summarizing text, extracting information, answering questions, translating languages or code, or even generating documentation, your prompt is your instruction manual. The clearer and more intentional you are, the better the AI performs.\n\nBut it’s not just what you say—it’s how you configure the model’s output. There are a few essential dials to know:\n\n- **Output length:** Be specific. Too short, and you miss details; too long, and the model might ramble or fill with fluff. Example: “Summarize this article in 100 words.” or \"Explain quantum physics in a tweet-length message\"\n- **Sampling controls:** These include temperature, top-K, and top-P. Temperature controls randomness in the LLM's responses. At temperature 0, responses are deterministic and predictable – great for factual queries. Higher temperatures introduce creativity and variation – better for brainstorming or creative writing. Top-K and top-P further shape how “adventurous” the model is in picking the next word. For most tasks, a temperature of 0.2, top-P of 0.95, and top-K of 30 is a sweet spot for coherence with a dash of creativity.\n- **Watch for repetition loops:** If you notice the model repeating itself, try tweaking these settings—especially temperature and top-K.\n\nWhen it comes to crafting prompts, there’s a whole toolkit of techniques:\n\n- **Zero-shot prompting** is the simplest: just ask your question or give a command. \"Write a short poem about autumn.\"\n- **One-shot and few-shot prompting** involve giving one or more examples. This is especially helpful for classification or when you want a specific output structure. For example:\n\n```\nReview: \"This movie was hilarious and heartwarming.\"\nSentiment: Positive\n\nReview: \"The plot was confusing and dull.\"\nSentiment:\n```\n- **System, contextual, and role prompting** add another layer of sophistication:\n    - **System prompts** set the “big picture” context—like telling the model to always return results in JSON, or to answer respectfully. Example: \"You are an expert Python programmer helping debug code.\"\n    - **Contextual prompts** give task-specific instructions or information for the current task: \"Here's a function that's throwing an IndexError.\"\n    - **Role prompts** let you assign a persona or style, like “You are a motivational speaker. Explain blockchain to a beginner.”\n\nSome advanced techniques can boost performance on tricky tasks:\n\n- **Step-back prompting:** First ask the model a general question, then feed its answer into a more specific prompt.\n- **Chain of Thought (CoT):** Encourage the model to “think aloud” by breaking down its reasoning step by step.\n- **Self-consistency:** Run the same prompt multiple times with higher randomness, then pick the most common answer for reliability.\n- **Tree of Thoughts (ToT):** Explore multiple reasoning paths at once, not just one.\n- **ReAct (Reason \\& Act):** Combine reasoning with actions, like calling APIs or searching the web, for agent-like behavior.\n- **Automatic Prompt Engineering:** Use the model itself to generate and refine new prompts—a kind of meta-prompting.\n\n\n\nFor more complex reasoning tasks, techniques like **Chain of Thought** (CoT) and **Tree of Thoughts** (ToT) can dramatically improve results. Chain of Thought encourages the model to \"think aloud\" by showing its reasoning step by step:\n\n```\nQuestion: If John has 5 apples and gives 2 to Mary, then buys 3 more and eats 1, how many apples does John have?\nThinking: John starts with 5 apples. He gives 2 to Mary, so now he has 5-2=3 apples. Then he buys 3 more, so now he has 3+3=6 apples. Finally, he eats 1, so he has 6-1=5 apples.\nAnswer: 5 apples\n```\n\nPrompt engineering isn’t just for text. While it’s invaluable for code - writing, translating, explaining, analysis and reasoning all benefit from well-crafted prompts.\n\nSo, what makes a good prompt? Here’s what I’ve found works best:\n\n- **Provide examples**—they’re the best way to “teach” the model.\n- **Keep it simple and clear.** If it confuses you, it’ll confuse the AI.\n- **Use action verbs:** Analyze, Summarize, Generate, List, etc.\n- **Be specific about the output.** “Return the answer as a JSON object with keys ‘city’ and ‘population’.”\n- **Prefer instructions over constraints:** “Write in a formal tone” is clearer than “Don’t be informal.”\n- **Control token length:** “Explain quantum physics in a tweet.”\n- **Use variables when you use repetitive prompts with small differences:** “Variables: {city}=Amsterdam \nPrompt: You are a travel guide. Tell me a fact about the city: {city}.”\n- **Experiment with styles and formats.** Try different prompt types, output formats (like JSON/XML), and even mix up your examples.\n- **Document your attempts.** Prompt engineering is iterative—track what works and what doesn’t.\n\nFor more complex tasks, a structured prompt format can be a game-changer. Here’s a sample template you can adapt:\n\n```\n<OBJECTIVE_AND_PERSONA>\nYou are a [insert a persona, such as a \"math teacher\" or \"automotive expert\"]. Your task is to...\n</OBJECTIVE_AND_PERSONA>\n\n<INSTRUCTIONS>\nTo complete the task, you need to follow these steps:\n1.\n2.\n...\n</INSTRUCTIONS>\n\n------------- Optional Components ------------\n\n<CONSTRAINTS>\nDos and don'ts for the following aspects\n1. Dos\n2. Don'ts\n</CONSTRAINTS>\n\n<CONTEXT>\nThe provided context\n</CONTEXT>\n\n<OUTPUT_FORMAT>\nThe output format must be\n1.\n2.\n...\n</OUTPUT_FORMAT>\n\n<FEW_SHOT_EXAMPLES>\nHere we provide some examples:\n1. Example #1\n    Input:\n    Thoughts:\n    Output:\n...\n</FEW_SHOT_EXAMPLES>\n\n<RECAP>\nRe-emphasize the key aspects of the prompt, especially the constraints, output format, etc.\n</RECAP>\n```\n\nLet's see this in action with a simple example:\n```\n<OBJECTIVE_AND_PERSONA>\nYou are a travel blogger known for concise, vivid descriptions. Your task is to create engaging city descriptions.\n</OBJECTIVE_AND_PERSONA>\n\n<INSTRUCTIONS>\nCreate a 100-word description that captures the essence of the city I name.\n</INSTRUCTIONS>\n\n<OUTPUT_FORMAT>\nA single paragraph of exactly 100 words that includes:\n1. A striking opening line\n2. Mention of one famous landmark\n3. Reference to local cuisine\n4. A sensory detail (sound, smell, etc.)\n</OUTPUT_FORMAT>\n\n<FEW_SHOT_EXAMPLES>\nCity: Paris\nOutput: Paris whispers romance in every cobblestone alley and tree-lined boulevard. The Eiffel Tower stands as an iron sentinel, watching over centuries of love stories unfolding beneath its gaze. In quaint cafés, the aroma of fresh croissants mingles with rich espresso, tempting passersby to pause and indulge. Street musicians fill the air with accordion melodies that dance between historic buildings. Whether bathed in golden morning light or twinkling with evening stars, the City of Light captivates with a timeless charm that transforms visitors into lifelong admirers.\n</FEW_SHOT_EXAMPLES>\n\nCity: Tokyo\n```\n\nPrompt engineering is both an art and a science, requiring practice, experimentation, and a good understanding of how LLMs work. As these models continue to evolve, so too will the techniques we use to communicate with them. But mastering these fundamentals will give you a solid foundation for getting the most out of AI tools, whether for personal projects, creative endeavors, or professional applications.\n\nThe journey of learning to speak AI's language is just the beginning. If you're interested in diving deeper into this fascinating field, I highly recommend checking out [Lee Boonstra's book](https://drive.google.com/file/d/1AbaBYbEa_EbPelsT40-vj64L-2IwUJHy/view) on Prompt Engineering, which provided the insights for this blog post. Even the [Google's learning center material](https://cloud.google.com/vertex-ai/generative-ai/docs/learn/prompts/prompt-design-strategies) around prompt engineering is a good starting point.\n\nWhat prompt engineering techniques have you found most effective? I'd love to hear about your experiences.\n","title":"The Art of Prompt Engineering","description":"Unlock the secrets of prompt engineering with this practical guide inspired by Lee Boonstra’s book. Learn how crafting clear, targeted prompts can dramatically improve your interactions with AI—whether you’re summarizing text, generating code, or extracting information. This post explores essential techniques, configuration tips, real-world examples, and best practices to help you communicate with large language models more effectively and creatively. Perfect for anyone looking to master the language of AI and get the most out of today’s generative tools","date":"2025-04-19","author":"Sony Mathew","readingTime":8,"categories":["Technology"],"tags":["Prompt Engineering","AI","LLM","Prompts","Generative AI","AI Best Practices","AI Prompt Design","AI Examples","AI assisted writing","Large Language Models"],"toc":false,"bannerImage":"/images/posts/the-art-of-prompt-engineering/art-of-prompting.jpg"}},"__N_SSG":true}